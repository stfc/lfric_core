!-----------------------------------------------------------------------------
! Copyright (c) 2017,  Met Office, on behalf of HMSO and Queen's Printer
! For further details please refer to the file LICENCE.original which you
! should have received as part of this distribution.
!-----------------------------------------------------------------------------

module compute_tri_precon_kernel_mod_test

  use constants_mod,                 only : i_def, r_def
  use field_mod,                     only : field_type, &
                                            field_proxy_type
  use fs_continuity_mod,             only : W0, W3
  use function_space_mod,            only : function_space_type
  use function_space_collection_mod, only : function_space_collection_type, &
                                            function_space_collection
  use mesh_collection_mod,           only : mesh_collection_type, &
                                            mesh_collection
  use pFUnit_Mod
  use timestepping_config_mod,   only : timestepping_runge_kutta_method_ssp4, &
                                        timestepping_method_semi_implicit
  use yaxt,                      only : xt_initialize, xt_finalize
  use mpi_mod,                   only : store_comm, clear_comm

  implicit none

  private
  public :: compute_tri_precon_test_type, test_all

  @TestCase
  type, extends(MPITestCase) :: compute_tri_precon_test_type
    private
    type(function_space_type), pointer :: w0_fs => null()
    type(function_space_type), pointer :: w3_fs => null()
    type(field_type)                   :: exner
    type(field_type)                   :: chi(3)
    type(field_type)                   :: rho
    type(field_type)                   :: theta
    type(field_type)                   :: A0
    type(field_type)                   :: AP
    type(field_type)                   :: AM
    real(r_def), allocatable           :: diff_basis_chi(:,:,:)
  contains
    procedure setUp
    procedure tearDown
    procedure test_all
  end type compute_tri_precon_test_type

  integer(i_def), parameter :: element_order = 0

  real(r_def), parameter :: gravity = 10.0_r_def
  real(r_def), parameter :: radius  = 6000000_r_def
  real(r_def), parameter :: omega   = 8.0E-5_r_def
  real(r_def), parameter :: p_zero  = 100000.0_r_def
  real(r_def), parameter :: rd      = 300.0_r_def
  real(r_def), parameter :: cp      = 1000.0_r_def
  real(r_def), parameter :: scaling = 1.0_r_def

  integer(i_def), parameter :: method    = timestepping_method_semi_implicit
  integer(i_def), parameter :: rk_method = timestepping_runge_kutta_method_ssp4
  real(r_def),    parameter :: dt = 10.0_r_def
  real(r_def), parameter    :: alpha   = 0.5_r_def
  real(r_def), parameter    :: tau_u   = 0.5_r_def
  real(r_def), parameter    :: tau_t   = 0.5_r_def
  real(r_def), parameter    :: tau_r   = 0.5_r_def
  integer(i_def), parameter :: nout = 1_i_def
  integer(i_def), parameter :: nin  = 1_i_def
  real(r_def), parameter    :: spinup_period = 0.0_r_def
  logical, parameter :: spinup_winds  = .false.
  logical, parameter :: spinup_alpha  = .false.

contains

  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  subroutine setUp( this )

    use base_mesh_config_mod,      only : base_mesh_geometry_planar, &
                                          base_mesh_partitioner_planar
    use finite_element_config_mod, only : finite_element_cellshape_quadrilateral
    use gungho_feign_config_mod,   only : feign_base_mesh_config,           &
                                          feign_planet_config,              &
                                          feign_timestepping_config
    use mesh_mod,                  only : PLANE_BI_PERIODIC

    implicit none

    class(compute_tri_precon_test_type), intent(inout) :: this

    type(field_proxy_type) :: chi_p, exner_p
    integer(i_def)         :: i
    integer(i_def)         :: ndf_chi, diff_dim_chi, ndf_exner
    integer(i_def)         :: mesh_id

    ! Initialise YAXT
    call xt_initialize(this%getMpiCommunicator())
    !Store the MPI communicator for later use
    call store_comm(this%getMpiCommunicator())

    call feign_base_mesh_config( filename='foo', prime_mesh_name='unit_test', &
                                 geometry=base_mesh_geometry_planar,          &
                                 partitioner=base_mesh_partitioner_planar,    &
                                 fplane=.false., f_lat_deg=0.0_r_def )

    call feign_planet_config( gravity=gravity, radius=radius, omega=omega, &
                              rd=rd, cp=cp, p_zero=p_zero,                 &
                              scaling_factor=scaling )

    call feign_timestepping_config(    &
         method=method,                &
         dt=dt,                        &
         alpha=alpha,                  &
         tau_u=tau_u,                  &
         tau_t=tau_t,                  &
         tau_r=tau_r,                  &
         outer_iterations=nout,        &
         inner_iterations=nin,         &
         runge_kutta_method=rk_method, &
         spinup_period=spinup_period,  &
         spinup_alpha=spinup_alpha,    &
         spinup_winds=spinup_winds )

    ! Create top level mesh collection
    mesh_collection = mesh_collection_type()
    ! Create top level function space collection
    function_space_collection = function_space_collection_type()

    ! Dummy mesh mod has 9 cells, 3 layers and is uniform in vertical
    mesh_id = mesh_collection%add_unit_test_mesh( PLANE_BI_PERIODIC )

    this%w0_fs => function_space_collection%get_fs(mesh_id, element_order, W0)
    this%w3_fs => function_space_collection%get_fs(mesh_id, element_order, W3)

    this%A0    = field_type( vector_space = this%w3_fs )
    this%AP    = field_type( vector_space = this%w3_fs )
    this%AM    = field_type( vector_space = this%w3_fs )
    this%exner = field_type( vector_space = this%w3_fs )
    this%rho   = field_type( vector_space = this%w3_fs )
    this%theta = field_type( vector_space = this%w0_fs )
    do i = 1,3
      this%chi(i) = field_type( vector_space = this%w0_fs )
    end do

    ! Get dims of the basis array
    chi_p    = this%chi(1)%get_proxy()
    ndf_chi  = chi_p%vspace%get_ndf()
    diff_dim_chi = chi_p%vspace%get_dim_space_diff()

    exner_p   = this%exner%get_proxy()
    ndf_exner = exner_p%vspace%get_ndf()

    allocate(this%diff_basis_chi(diff_dim_chi, ndf_chi, ndf_exner))

  end subroutine setUp

  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  subroutine tearDown( this )

    use gungho_configuration_mod, only: final_configuration

    implicit none

    class(compute_tri_precon_test_type), intent(inout) :: this

    deallocate( this%diff_basis_chi )

    call function_space_collection%clear()
    call mesh_collection%clear()
    call final_configuration()

    ! Finalise YAXT
    call xt_finalize()
    ! Clear the stored MPI communicator
    call clear_comm()

  end subroutine tearDown

  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  @Test( npes=[1] )
  subroutine test_all( this )

    use compute_tri_precon_kernel_mod, only: compute_tri_precon_code
    use planet_config_mod,             only: kappa
    use function_space_mod,            only: DIFF_BASIS

    implicit none

    class(compute_tri_precon_test_type), intent(inout) :: this

    real(r_def), parameter    :: dx = 6000.0_r_def, &
                                 dy = 1000.0_r_def, &
                                 dz = 2000.0_r_def
    real(r_def), parameter    :: tol = 1.0e-10_r_def
    real(r_def)               :: answer
    type(field_proxy_type )   :: chi_p(3)

    integer                   :: i, j, k, cell, err

    integer                   :: nlayers, nqp_h, nqp_v
    integer                   :: ndf_w0, ndf_w3
    integer                   :: undf_w0, undf_w3

    integer                   :: ndf_chi, diff_dim_chi
    integer                   :: df_w3, df_chi


    integer                   :: element_order
    integer, pointer          :: map_w3(:), map_w0(:) => null()
    real(kind=r_def), pointer :: nodes_w3(:,:) => null()
    type(field_proxy_type)    :: exner_proxy, rho_proxy, theta_proxy, &
                                 A0_proxy, AM_proxy, AP_proxy

    ! Make a coordinate field with a function space
    do i = 1,3
      chi_p(i) = this%chi(i)%get_proxy()
    end do

    ! Compute coordinates
    cell = 1
    do j = 1,3
      do i = 1,3
        map_w0 => chi_p(1)%vspace%get_cell_dofmap( cell )
        do k = 0,3
          chi_p(1)%data(map_w0(1) + k) = real(i-1)*dx
          chi_p(2)%data(map_w0(1) + k) = real(j-1)*dy
          chi_p(3)%data(map_w0(1) + k) = real(k)  *dz
        end do
        cell = cell + 1
      end do
    end do

    ! Test kernel
    exner_proxy = this%exner%get_proxy()
    rho_proxy   = this%rho%get_proxy()
    theta_proxy = this%theta%get_proxy()
    A0_proxy  = this%A0%get_proxy()
    AP_proxy  = this%AP%get_proxy()
    AM_proxy  = this%AM%get_proxy()

    nlayers  = exner_proxy%vspace%get_nlayers()
    nodes_w3 => exner_proxy%vspace%get_nodes()
    ndf_w3   = exner_proxy%vspace%get_ndf( )
    undf_w3  = exner_proxy%vspace%get_undf()

    ndf_w0  = theta_proxy%vspace%get_ndf( )
    undf_w0 = theta_proxy%vspace%get_undf()

    ndf_chi = chi_p(1)%vspace%get_ndf( )
    diff_dim_chi = chi_p(1)%vspace%get_dim_space_diff( )

    ! Evaluate the basis function
    do df_w3 = 1, ndf_w3
      do df_chi = 1, ndf_chi
        this%diff_basis_chi(:,df_chi,df_w3) = chi_p(1)%vspace%call_function(DIFF_BASIS,df_chi,nodes_w3(:,df_w3))
      end do
    end do

    cell = 5

    map_w3 => exner_proxy%vspace%get_cell_dofmap( cell )
    map_w0 => theta_proxy%vspace%get_cell_dofmap( cell )

    ! Create the data
    exner_proxy%data(:) = 1.5_r_def
    rho_proxy%data(:)   = 1.5_r_def
    theta_proxy%data(:) = 300.0_r_def

    call compute_tri_precon_code( nlayers,                                   &
                                  A0_proxy%data,                             &
                                  AP_proxy%data,                             &
                                  Am_proxy%data,                             &
                                  theta_proxy%data,                          &
                                  exner_proxy%data,                          &
                                  rho_proxy%data,                            &
                                  chi_p(1)%data,                             &
                                  chi_p(2)%data,                             &
                                  chi_p(3)%data,                             &
                                  ndf_w3, undf_w3, map_w3,                   &
                                  ndf_w0, undf_w0, map_w0,                   &
                                  ndf_w0, undf_w0, map_w0,                   &
                                  this%diff_basis_chi  &
                                 )

    answer = 0.0_r_def
    k = 0
    @assertEqual(answer, AM_proxy%data(map_w3(1)+k), tol)
    k = nlayers - 1
    @assertEqual(answer, AP_proxy%data(map_w3(1)+k), tol)
    
    answer = - (tau_u*dt/dz)**2*cp*theta_proxy%data(map_w0(1))
    k = 1
    @assertEqual(answer, AP_proxy%data(map_w3(1)+k), tol)
    @assertEqual(answer, AM_proxy%data(map_w3(1)+k), tol)
    
    answer = ((1.0_r_def- kappa)/kappa * 1.0_r_def/exner_proxy%data(1) - 2.0_r_def*answer)
    @assertEqual(answer, A0_proxy%data(map_w3(1)+k), tol)

  end subroutine test_all

end module compute_tri_precon_kernel_mod_test
